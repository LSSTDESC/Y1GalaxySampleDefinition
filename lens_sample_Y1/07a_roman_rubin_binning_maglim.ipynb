{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c3bd8a-bb46-47e4-bd0e-8d8f523e206e",
   "metadata": {},
   "source": [
    "## **07.a Binning**,\n",
    "#### Authors: **Amanda Farias (afariassantos2@gmail.com), Iago Lopes (iagolops2012@gmail.com), Bruno Moraes (bruno.a.l.moraes@gmail.com)**\n",
    "#### Creation date: **09/13/2024**\n",
    "#### Last Verifed to Run: **11/19/2024** (by @iago)\n",
    "\n",
    "\n",
    "The objective of this notebook is to obtain the binned redshift distribution of the dataset. First, we will create the redshift distribution for each sample: for the Roman Rubin (true) redshifts, we will use the *TrueNZHistogrammer* to generate histograms, and for the observed redshifts, we will stack the PDFs using the *NaiveStackSummarizer*. The resulting distribution will then be binned according to the __[LSST DESC SRD](https://arxiv.org/pdf/1809.01669)__. The lens sample, using the MagLim cut, will be divided into 5 bins with a width of $\\Delta z$ = 0.2, ranging from 0.2 to 1.2. The source sample will be divided into 5 bins, each containing an equal number of galaxies.\n",
    "\n",
    "\n",
    "##### Logistics: This notebook is intended to be run through the Jupyter Lab NERSC interface available in __[Jupyter nersc](https://jupyter.nersc.gov/)__ in the **desc-python** kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812cb317-492a-4e99-aa4a-83fc4d9d0897",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>ATTENTION:</b> We intend to change the binning functions for RAIL functions. It's not implemented yet.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d476aa53-7c6e-4d08-b26c-a5120f28b573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np \n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import integrate\n",
    "from rail.estimation.algos.naive_stack import NaiveStackSummarizer\n",
    "from rail.estimation.algos.true_nz import TrueNZHistogrammer\n",
    "from rail.core.stage import RailStage\n",
    "import scipy\n",
    "import tables_io\n",
    "from scipy.special import erf\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import qp\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from rail.evaluation.dist_to_dist_evaluator import DistToDistEvaluator\n",
    "\n",
    "from rail.core.data import (\n",
    "    QPHandle,\n",
    "    TableHandle,\n",
    "    Hdf5Handle,\n",
    ")\n",
    "\n",
    "import gc\n",
    "from binning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc4a40-1f37-4457-925f-838cb923601b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca6920e-4ea7-421f-ac87-0438d9e81cc2",
   "metadata": {},
   "source": [
    "## Loading the dataset \n",
    "This dataset was evaluated in notebook 04a and it contains the true redshift, observed redshift and the PDFs of each galaxy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798a1ec-78f6-4ab3-b09e-be8f5ae64a9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>ATTENTION:</b> In order to run this notebook on your NERSC account, please update the kernel to use your username.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bce88d-b6d5-47ca-bb16-7e532ab7b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "nersc_name = 'iago'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3a306-98b4-467a-b6cc-bbf90c7671e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"/pscratch/sd/\" + nersc_name[0] + \"/\" + nersc_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8756d-3a81-4371-a873-0c150415b566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############## Download the catalog with the photo-z #############\n",
    "\n",
    "result = DS.read_file('pdfs_data', QPHandle, \n",
    "                      f'{path}/results_y1/output_estimate_a_roman_fzb_y1_10sig.hdf5')\n",
    "\n",
    "############### Max redshift ##############\n",
    "z_max = result().build_tables()['meta']['xvals'][0][-1]\n",
    "\n",
    "############ X values for plot ############\n",
    "zgrid = np.linspace(0, z_max, 301)\n",
    "    \n",
    "################## PDFS ##################\n",
    "pdfs = result().build_tables()['data']['yvals']\n",
    "\n",
    "########## Median or mode of PDF ##########\n",
    "mode = result().mode(zgrid)\n",
    "\n",
    "#### Array of photo-z with 132891 galaxies\n",
    "zphot  = np.array([valor for sublista in mode for valor in sublista])\n",
    "\n",
    "##############################################\n",
    "################ True redshift ###############\n",
    "##############################################\n",
    "\n",
    "catalog = pd.read_csv(f'{path}/roman_rubin_y1_a_test_10sig.csv', sep=' ')\n",
    "catalog['zphot'] = zphot\n",
    "ztrue = catalog['redshift']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7ef6b-e4d0-4946-9d52-3bc4d4a50a69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Observed redshift distribution\n",
    "\n",
    "The Naive stack method sums the PDFs of all galaxies without considering weights or other parameters. In the ``NaiveStackSummarizer`` from RAIL, the entire redshift range is divided into bins, and the PDFs of all galaxies within each bin are summed. Subsequently, the code normalizes these summed PDFs.\n",
    "\n",
    "For our configuration, we utilize the redshift range defined by the output, starting from 0 to z_max, and divide this range into 300 bins.\n",
    "\n",
    "For a more detailed explanation of each component in the ``NaiveStackSummarizer``, please refer to the __[RAIL documentation](https://github.com/LSSTDESC/rail/blob/6f4e15315962b3010dbd52eb2c4e308710df9b87/docs/source/new_rail_stage.rst#L90)__ on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89badc-7375-40b9-bfa8-4637c429c97d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LENS MagLim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8cfe64-0ee8-42d0-8c44-702bb3ca9114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_vector = [3.0,3.5,4.0,4.5]\n",
    "b_vector = [17.5,18.0,18.5,19.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993e17e-3149-4101-bcdb-dafdb97305ad",
   "metadata": {},
   "source": [
    "#### Analyzing the metrics for all cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283cd23-bf1d-4049-8d12-2a54af3e3e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "metrics = {}\n",
    "for a in a_vector:\n",
    "    for b in b_vector:\n",
    "        mask = catalog['mag_i_lsst'] < b + a*catalog['zphot']\n",
    "        total = len(catalog[mask]['redshift'])\n",
    "\n",
    "        create_filtered_hdf5_files(mask, path, zphot)\n",
    "        process_bins()\n",
    "        create_histograms()\n",
    "        sizes = []\n",
    "        \n",
    "        for i in range(5):\n",
    "            mask_iter = (catalog['mag_i_lsst'] < b + a*catalog['zphot']) & (catalog[\"mag_i_lsst\"] > 17.5) & (catalog['zphot'] > 0.2 + 0.2*i) & (catalog['zphot'] < 0.4 + 0.2*i)\n",
    "            zphot_lens = zphot[mask_iter]\n",
    "            pdfs_mask = result.data[mask_iter]\n",
    "            tables = pdfs_mask.build_tables()\n",
    "            sizes.append(tables['data']['yvals'].shape[0])\n",
    "            pdfs_qp = DS.add_data(key=f'maglim_pdfs_{i}', handle_class=QPHandle, data=pdfs_mask)\n",
    "            \n",
    "    \n",
    "            naive_stack_lens_phot  = NaiveStackSummarizer.make_stage(zmin=0.0, zmax=3.0, nzbins=301, nsamples = 25, hdf5_groupname='', chunk_size=400000, name=f'naive_stack_lens_phot_bin{i}')\n",
    "            naive_results_lens_phot = naive_stack_lens_phot.summarize(pdfs_qp)\n",
    "\n",
    "        metrics[f'{a}_{b}'] = metrics_sample(num_bins=5, param=(a,b), sizes=sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e7188a-0cd4-483e-b539-aac1a4ab1a39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['#4d4d4d', '#08306b', '#6baed6', '#ffcc00', '#ffb347']\n",
    "\n",
    "def plot_metrics(metric_index, title, ylabel):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(5):\n",
    "        x_values = []\n",
    "        y_values = []\n",
    "        for a in a_vector:\n",
    "            for b in b_vector:\n",
    "                x_values.append(f'{a}_{b}')\n",
    "                y_values.append(metrics[f'{a}_{b}'][metric_index][i])\n",
    "        plt.plot(x_values, y_values, color=colors[i], marker='o', label=f'Bin {i+1}')\n",
    "    plt.axhline(ls='--', color='black')\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.ylabel(ylabel, fontsize=16)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(loc='best', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(metric_index=0, title='Mean Bias', ylabel='Mean Bias')\n",
    "plot_metrics(metric_index=1, title='Sigma Bias', ylabel='Std Bias')\n",
    "plot_metrics(metric_index=2, title=r'$\\frac{N}{arcmin^2}$', ylabel=r'$\\frac{N}{arcmin^2}$')\n",
    "plot_metrics(metric_index=3, title=r'Sigma truth', ylabel=r'Sigma truth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c6ed7-066f-4504-a4ee-c1f1e93d94cc",
   "metadata": {},
   "source": [
    "### Binning for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c88ecc-fdde-4587-b465-bb09bd7c1d78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for a in a_vector:\n",
    "    for b in b_vector:\n",
    "        mask = catalog['mag_i_lsst'] < b + a*catalog['zphot']\n",
    "        total = len(catalog[mask]['redshift'])\n",
    "\n",
    "        create_filtered_hdf5_files(mask, path, zphot)\n",
    "        process_bins()\n",
    "        create_histograms()\n",
    "        sizes = []\n",
    "        \n",
    "        for i in range(5):\n",
    "            mask_iter = (catalog['mag_i_lsst'] < b + a*catalog['zphot']) & (catalog[\"mag_i_lsst\"] > 17.5) & (catalog['zphot'] > 0.2 + 0.2*i) & (catalog['zphot'] < 0.4 + 0.2*i)\n",
    "            zphot_lens = zphot[mask_iter]\n",
    "            pdfs_mask = result.data[mask_iter]\n",
    "            tables = pdfs_mask.build_tables()\n",
    "            sizes.append(tables['data']['yvals'].shape[0])\n",
    "            pdfs_qp = DS.add_data(key=f'maglim_pdfs_{i}', handle_class=QPHandle, data=pdfs_mask)\n",
    "            \n",
    "    \n",
    "            naive_stack_lens_phot  = NaiveStackSummarizer.make_stage(zmin=0.0, zmax=3.0, nzbins=301, nsamples = 25, hdf5_groupname='', chunk_size=400000, name=f'naive_stack_lens_phot_bin{i}')\n",
    "            naive_results_lens_phot = naive_stack_lens_phot.summarize(pdfs_qp)\n",
    "\n",
    "        plot_nz_from_bins(num_bins=5, param=(a,b), sizes=sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a3121-6fa1-42c6-99c3-eb5949bbf126",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SOURCE\n",
    "\n",
    "After defining which lens sample we are going to use, we can create the source sample by removing galaxies that are in lens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10fa8d-5259-45c8-b5ba-1232db183c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_galaxies = len(source_catalog)\n",
    "\n",
    "num_bins = 5\n",
    "galaxies_per_bin = num_galaxies // num_bins\n",
    "\n",
    "sorted_indices = np.argsort(source_catalog['zphot'])\n",
    "\n",
    "for bin_i in range(num_bins):\n",
    "    start_index = bin_i * galaxies_per_bin\n",
    "    end_index = start_index + galaxies_per_bin if bin_i < num_bins - 1 else num_galaxies\n",
    "\n",
    "\n",
    "    bin_indices = sorted_indices[start_index:end_index]\n",
    "\n",
    "    zphot_src = source_catalog.iloc[bin_indices]['zphot']  \n",
    "    pdfs_mag = result.data[mask][bin_indices]  \n",
    "    \n",
    "    mag_qp = DS.add_data(key='src_pdfs', handle_class=QPHandle, data=pdfs_mag)\n",
    "\n",
    "    naive_stack_src_phot = NaiveStackSummarizer.make_stage(\n",
    "        zmin=0.0, zmax=3.0, nzbins=301, nsamples=25, \n",
    "        hdf5_groupname='', chunk_size=400000, \n",
    "        name=f'naive_stack_src_phot_bin{bin_i}'\n",
    "    )\n",
    "    naive_results_src_phot = naive_stack_src_phot.summarize(mag_qp)\n",
    "    \n",
    "    del zphot_src, pdfs_mag, mag_qp, naive_results_src_phot\n",
    "    gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f590f3-2082-4e5d-9fd4-7c0b1afde0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = ['#4d4d4d', '#08306b', '#6baed6', '#ffcc00', '#ffb347']\n",
    "\n",
    "lens_srd = pd.read_csv('/global/u1/' + nersc_name[0] + \"/\" + nersc_name + '/lens_SRD', sep=' ', index_col=False).T #Change here the location of SRD lens file\n",
    "bins = [float(x) for x in np.array(lens_srd.index)]\n",
    "\n",
    "src_srd=pd.read_csv('/global/u1/' + nersc_name[0] + \"/\" + nersc_name + '/src_SRD', sep=' ',index_col=False).T\n",
    "bins = [float(x) for x in np.array(lens_srd.index)]\n",
    "bins = np.round(np.array(bins),4)\n",
    "\n",
    "def plot_nz_from_bins(num_bins):\n",
    "    plt.figure(figsize=(12, 8))  # Create a new figure for plotting\n",
    "    \n",
    "    for i, bin_num in enumerate(range(1, num_bins + 1)):\n",
    "        # Read the data from the HDF5 file\n",
    "        input_file_true = qp.read(f'true_NZ_true_nz_src_{bin_num}.hdf5')\n",
    "        input_file_phot = DS.read_file('pdfs_data', QPHandle, \n",
    "                      f'single_NZ_naive_stack_src_phot_bin{bin_num-1}.hdf5')\n",
    "        \n",
    "        y_true = input_file_true.objdata()['pdfs'][0]\n",
    "        x_true = input_file_true.metadata()['bins'][0]\n",
    "        \n",
    "        y_phot = input_file_phot().build_tables()['data']['yvals'][0]\n",
    "        x_phot = input_file_phot().build_tables()['meta']['xvals'][0]\n",
    "\n",
    "        # Smoothing the true curve before normalizing\n",
    "        cs_true = UnivariateSpline(x_true[:-1], y_true)\n",
    "        cs_true.set_smoothing_factor(1)  # Adjust the smoothing factor here\n",
    "\n",
    "        smoothed_y_true = cs_true(x_true[:-1])\n",
    "        \n",
    "        # Normalize the area under the smoothed true curve\n",
    "        area_true = np.trapz(smoothed_y_true, x_true[:-1])\n",
    "        y_true_normalized = smoothed_y_true / area_true  # Normalized to area 1\n",
    "        \n",
    "        # Normalize the area under the photometric curve\n",
    "        area_phot = np.trapz(y_phot, x_phot)\n",
    "        y_phot_normalized = y_phot / area_phot  # Normalized to area 1\n",
    "\n",
    "        # Plot the photometric and true curves\n",
    "        plt.plot(x_phot, y_phot_normalized, color=colors[i], linewidth=2)\n",
    "        plt.plot(x_true[:-1], y_true_normalized, color=colors[i], linestyle='--', linewidth=2)\n",
    "        plt.plot(bins,src_srd[i],color='red',linewidth=2)\n",
    "        \n",
    "        \n",
    "    plt.axvspan(0, 0.4, color=colors[0], alpha=0.3)  \n",
    "    plt.axvspan(0.4, 0.6, color=colors[1], alpha=0.3)  \n",
    "    plt.axvspan(0.6, 0.8, color=colors[2], alpha=0.3)  \n",
    "    plt.axvspan(0.8, 1.0, color=colors[3], alpha=0.3)  \n",
    "    plt.axvspan(1.0, 3, color=colors[4], alpha=0.3)  \n",
    "      \n",
    "    \n",
    "    plt.plot([],[], label=f'True Bin',linewidth=2,ls='--',color=colors[i])\n",
    "    plt.plot([],[], label=f'Phot Bin',linewidth=2,color=colors[i])\n",
    "    plt.plot([],[], label=f'LSST DESC SRD Y1',linewidth=2,color='red')\n",
    "        \n",
    "    # Customizing the plot\n",
    "    plt.xlabel('Redshift (z)', fontsize=18)\n",
    "    plt.ylabel('N(z)', fontsize=18)\n",
    "    plt.title('N(z) Distribution for src sample for the true and observed redshifts',fontsize=20)\n",
    "    plt.legend(fontsize=14,loc=1)\n",
    "    plt.ylim(0, 7)  # Adjusted for normalized values\n",
    "    plt.xlim(0, 3)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot N(z) for 5 bins\n",
    "plot_nz_from_bins(num_bins=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6b238-5942-4c35-9260-b5e88ff8a94d",
   "metadata": {},
   "source": [
    "# Roman Rubin sims redshift distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a22cb84-513e-4e62-9102-20f4064f0eed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872833ce-d980-40e3-ae14-b6666a2efe72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_final = 3.0\n",
    "b_final = 19.0\n",
    "\n",
    "lens_final = catalog[catalog['mag_i_lsst']<a_final*catalog['zphot']+b_final]\n",
    "\n",
    "mask = ~np.isin(catalog['galaxy_id'], lens_final['galaxy_id'])\n",
    "source_catalog = catalog[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d32add-617d-4402-9e0c-776c9a685ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the original HDF5 file (read mode)\n",
    "with h5py.File(f'{path}/roman_rubin_y1_a_test_10sig.hdf5', 'r') as old_file:\n",
    "    # Navigate inside the 'photometry' group in the old file\n",
    "    if 'photometry' in old_file:\n",
    "        old_photometry_group = old_file['photometry']\n",
    "        \n",
    "        # Get the redshift data from the old file\n",
    "        if 'zphot' in old_photometry_group:\n",
    "            redshift_data = old_photometry_group['zphot'][:]\n",
    "            redshift_data = redshift_data[catalog['mag_i_lsst']>a_final*catalog['zphot']+b_final]\n",
    "            \n",
    "            num_galaxies = len(redshift_data)\n",
    "            \n",
    "            num_bins = 5\n",
    "            galaxies_per_bin = num_galaxies // num_bins\n",
    "            \n",
    "            sorted_indices = np.argsort(redshift_data)\n",
    "            \n",
    "            for bin_i in range(1, num_bins + 1):\n",
    "                # Create a new HDF5 file for each bin (write mode)\n",
    "                with h5py.File(f'roman_rubin_test_binning_src_{bin_i}.hdf5', 'w') as new_file:\n",
    "\n",
    "                    photometry_group = new_file.create_group('photometry')\n",
    "\n",
    "                    start_index = (bin_i - 1) * galaxies_per_bin\n",
    "                    end_index = start_index + galaxies_per_bin if bin_i < num_bins else num_galaxies\n",
    "                    \n",
    "                    bin_indices = sorted_indices[start_index:end_index]\n",
    "\n",
    "                    columns_to_keep = [\n",
    "                        \"mag_err_g_lsst\", \"mag_err_i_lsst\", \"mag_err_r_lsst\", \n",
    "                        \"mag_err_u_lsst\", \"mag_err_y_lsst\", \"mag_err_z_lsst\",\n",
    "                        \"mag_g_lsst\", \"mag_i_lsst\", \"mag_r_lsst\", \n",
    "                        \"mag_u_lsst\", \"mag_y_lsst\", \"mag_z_lsst\", \n",
    "                        \"redshift\", \"galaxy_id\"\n",
    "                    ]\n",
    "\n",
    "                    # Loop through the columns and filter based on bin_indices\n",
    "                    for column in columns_to_keep:\n",
    "                        if column in old_photometry_group:\n",
    "                            data = old_photometry_group[column][:]\n",
    "                            data = data[catalog['mag_i_lsst']>a_final*catalog['zphot']+b_final]\n",
    "                            filtered_data = data[bin_indices]  \n",
    "                            \n",
    "                            if column == \"galaxy_id\":\n",
    "                                photometry_group.create_dataset(\"id\", data=filtered_data)\n",
    "                            else:\n",
    "                                photometry_group.create_dataset(column, data=filtered_data)\n",
    "                        else:\n",
    "                            print(f\"Column {column} not found in the 'photometry' group.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c87d87-0525-4c43-bd00-c557d8753b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(f'{path}/roman_rubin_y1_a_test_10sig.hdf5', 'r') as old_file:\n",
    "    # Navigate inside the 'photometry' group in the old file\n",
    "    if 'photometry' in old_file:\n",
    "        old_photometry_group = old_file['photometry']\n",
    "\n",
    "        if 'zphot' in old_photometry_group:\n",
    "            redshifts = old_photometry_group['zphot'][:]\n",
    "            redshifts = redshifts[catalog['mag_i_lsst']>a_final*catalog['zphot']+b_final]\n",
    "            num_galaxies = len(redshifts)\n",
    "            \n",
    "            sorted_indices = np.argsort(redshifts)\n",
    "            sorted_redshifts = redshifts[sorted_indices]\n",
    "            \n",
    "            num_bins = 5\n",
    "            galaxies_per_bin = num_galaxies // num_bins\n",
    "            \n",
    "            # Loop over each bin from 1 to 5\n",
    "            for bin_num in range(1, num_bins + 1):\n",
    "                \n",
    "                start_index = (bin_num - 1) * galaxies_per_bin\n",
    "                end_index = start_index + galaxies_per_bin if bin_num < num_bins else num_galaxies\n",
    "                \n",
    "                bin_indices = sorted_indices[start_index:end_index]\n",
    "                \n",
    "                class_ids = np.array([assign_class_id(z) for z in sorted_redshifts[start_index:end_index]])\n",
    "\n",
    "                # Function to create each bin file\n",
    "                def create_bin_file(bin_num, bin_indices, class_ids):\n",
    "                    output_file = f'output_tomo_binned_src_{bin_num}.hdf5'\n",
    "                    \n",
    "                    with h5py.File(output_file, 'w') as outfile:\n",
    "                        outfile.create_dataset('row_index', data=bin_indices)\n",
    "                        outfile.create_dataset('class_id', data=class_ids)\n",
    "                    \n",
    "                    print(f\"HDF5 file '{output_file}' created successfully!\")\n",
    "\n",
    "\n",
    "                create_bin_file(bin_num, bin_indices, class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce89d2-c9ba-43f9-a30b-d7e125da7f73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for i in range(5):\n",
    "    \n",
    "    true_nz_file = f'roman_rubin_test_binning_src_{i+1}.hdf5'\n",
    "    true_nz = DS.read_file('true_nz', path=true_nz_file, handle_class=TableHandle)\n",
    "    \n",
    "    # Create the histogram stage for the ith bin\n",
    "    nz_hist = TrueNZHistogrammer.make_stage(\n",
    "        name=f'true_nz_src_{i+1}',  \n",
    "        hdf5_groupname='photometry',\n",
    "        redshift_col='redshift',\n",
    "        zmin=0.0,\n",
    "        zmax=3.0,\n",
    "        nzbins=301\n",
    "    )\n",
    "    \n",
    "    \n",
    "    tomo_file = f\"output_tomo_binned_src_{i+1}.hdf5\"  \n",
    "    tomo_bins = DS.read_file('tomo_bins', path=tomo_file, handle_class=TableHandle)\n",
    "    \n",
    "    out_hist = nz_hist.histogram(true_nz, tomo_bins)\n",
    "    \n",
    "    print(f\"Histogram for bin {i+1} created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0c8c4-c425-403b-9f24-c7efe3f7d217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to read and plot results from each bin file\n",
    "def plot_nz_from_bins(num_bins):\n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    \n",
    "    for bin_num in range(1, num_bins + 1):\n",
    "        # Read the data from the HDF5 file\n",
    "        input_file = qp.read(f'true_NZ_true_nz_src_{bin_num}.hdf5')\n",
    "        \n",
    "        y_true = input_file.objdata()['pdfs'][0]\n",
    "        x_true = input_file.metadata()['bins'][0]\n",
    "\n",
    "        cs = UnivariateSpline(x_true[:-1], y_true)\n",
    "        cs.set_smoothing_factor(8) # adjust the smoothing of ztrue here !!!!\n",
    "\n",
    "        plt.plot(x_true[:-1], y_true, label=f'Bin {bin_num}')\n",
    "            \n",
    "    plt.xlabel('Redshift (z)')\n",
    "    plt.ylabel('N(z)')\n",
    "    plt.title('N(z) Distribution for src sample for the true redshifts')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim(0, 7.5)\n",
    "    plt.xlim(0, 3.0)\n",
    "    plt.show()\n",
    "\n",
    "plot_nz_from_bins(num_bins=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desc-python",
   "language": "python",
   "name": "test_rail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
